{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basé sur: A ten-minute introduction to sequence-to-sequence learning in Keras [ten_minute]\n",
    "\n",
    "\n",
    "[ten_minute]: https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Trivial [addnum]\n",
    "\n",
    "[trivial_addnum]: https://github.com/keras-team/keras/blob/master/examples/addition_rnn.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''An implementation of sequence to sequence learning for performing addition\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "Input may optionally be reversed, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "Two digits reversed:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "Three digits reversed:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "Four digits reversed:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "Five digits reversed:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n",
    "'''  # noqa\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "\n",
    "\n",
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n"
     ]
    }
   ],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras.layers' from '/Users/jmpoulin/miniconda3/lib/python3.6/site-packages/keras/layers/__init__.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per:\n",
    "# https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 33s 728us/step - loss: 1.8921 - acc: 0.3193 - val_loss: 1.7792 - val_acc: 0.3414\n",
      "Q 806+8   T 814  \u001b[91m☒\u001b[0m 108 \n",
      "Q 716+738 T 1454 \u001b[91m☒\u001b[0m 107 \n",
      "Q 38+60   T 98   \u001b[91m☒\u001b[0m 471 \n",
      "Q 61+856  T 917  \u001b[91m☒\u001b[0m 107 \n",
      "Q 53+205  T 258  \u001b[91m☒\u001b[0m 533 \n",
      "Q 186+920 T 1106 \u001b[91m☒\u001b[0m 108 \n",
      "Q 78+531  T 609  \u001b[91m☒\u001b[0m 107 \n",
      "Q 282+722 T 1004 \u001b[91m☒\u001b[0m 103 \n",
      "Q 584+69  T 653  \u001b[91m☒\u001b[0m 100 \n",
      "Q 3+813   T 816  \u001b[91m☒\u001b[0m 47  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 622us/step - loss: 1.7271 - acc: 0.3629 - val_loss: 1.6602 - val_acc: 0.3856\n",
      "Q 201+988 T 1189 \u001b[91m☒\u001b[0m 102 \n",
      "Q 577+493 T 1070 \u001b[91m☒\u001b[0m 1358\n",
      "Q 32+39   T 71   \u001b[91m☒\u001b[0m 232 \n",
      "Q 26+961  T 987  \u001b[91m☒\u001b[0m 702 \n",
      "Q 56+628  T 684  \u001b[91m☒\u001b[0m 776 \n",
      "Q 454+15  T 469  \u001b[91m☒\u001b[0m 555 \n",
      "Q 37+778  T 815  \u001b[91m☒\u001b[0m 808 \n",
      "Q 492+557 T 1049 \u001b[91m☒\u001b[0m 102 \n",
      "Q 772+923 T 1695 \u001b[91m☒\u001b[0m 1388\n",
      "Q 67+92   T 159  \u001b[91m☒\u001b[0m 108 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 622us/step - loss: 1.5945 - acc: 0.4050 - val_loss: 1.5329 - val_acc: 0.4232\n",
      "Q 42+11   T 53   \u001b[91m☒\u001b[0m 11  \n",
      "Q 7+91    T 98   \u001b[91m☒\u001b[0m 11  \n",
      "Q 310+5   T 315  \u001b[91m☒\u001b[0m 131 \n",
      "Q 25+743  T 768  \u001b[91m☒\u001b[0m 589 \n",
      "Q 994+29  T 1023 \u001b[91m☒\u001b[0m 901 \n",
      "Q 8+531   T 539  \u001b[91m☒\u001b[0m 841 \n",
      "Q 766+4   T 770  \u001b[91m☒\u001b[0m 776 \n",
      "Q 364+7   T 371  \u001b[91m☒\u001b[0m 441 \n",
      "Q 300+3   T 303  \u001b[91m☒\u001b[0m 331 \n",
      "Q 987+21  T 1008 \u001b[91m☒\u001b[0m 901 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 645us/step - loss: 1.4239 - acc: 0.4694 - val_loss: 1.3331 - val_acc: 0.5052\n",
      "Q 8+129   T 137  \u001b[91m☒\u001b[0m 111 \n",
      "Q 411+24  T 435  \u001b[91m☒\u001b[0m 445 \n",
      "Q 393+924 T 1317 \u001b[91m☒\u001b[0m 1318\n",
      "Q 890+682 T 1572 \u001b[91m☒\u001b[0m 1658\n",
      "Q 62+657  T 719  \u001b[91m☒\u001b[0m 633 \n",
      "Q 499+68  T 567  \u001b[91m☒\u001b[0m 543 \n",
      "Q 28+152  T 180  \u001b[91m☒\u001b[0m 201 \n",
      "Q 820+918 T 1738 \u001b[91m☒\u001b[0m 1701\n",
      "Q 70+253  T 323  \u001b[91m☒\u001b[0m 201 \n",
      "Q 870+7   T 877  \u001b[91m☒\u001b[0m 888 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 642us/step - loss: 1.2707 - acc: 0.5301 - val_loss: 1.1987 - val_acc: 0.5627\n",
      "Q 192+44  T 236  \u001b[91m☒\u001b[0m 216 \n",
      "Q 837+2   T 839  \u001b[91m☒\u001b[0m 838 \n",
      "Q 72+2    T 74   \u001b[91m☒\u001b[0m 80  \n",
      "Q 432+27  T 459  \u001b[91m☒\u001b[0m 476 \n",
      "Q 595+729 T 1324 \u001b[91m☒\u001b[0m 1348\n",
      "Q 841+7   T 848  \u001b[91m☒\u001b[0m 858 \n",
      "Q 82+78   T 160  \u001b[91m☒\u001b[0m 146 \n",
      "Q 180+976 T 1156 \u001b[91m☒\u001b[0m 1108\n",
      "Q 29+81   T 110  \u001b[91m☒\u001b[0m 106 \n",
      "Q 208+177 T 385  \u001b[91m☒\u001b[0m 416 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 624us/step - loss: 1.1504 - acc: 0.5764 - val_loss: 1.0888 - val_acc: 0.6001\n",
      "Q 20+166  T 186  \u001b[91m☒\u001b[0m 287 \n",
      "Q 462+823 T 1285 \u001b[91m☒\u001b[0m 1220\n",
      "Q 0+712   T 712  \u001b[91m☒\u001b[0m 717 \n",
      "Q 73+487  T 560  \u001b[91m☒\u001b[0m 544 \n",
      "Q 750+450 T 1200 \u001b[91m☒\u001b[0m 1201\n",
      "Q 432+4   T 436  \u001b[91m☒\u001b[0m 444 \n",
      "Q 428+71  T 499  \u001b[91m☒\u001b[0m 488 \n",
      "Q 163+485 T 648  \u001b[92m☑\u001b[0m 648 \n",
      "Q 38+38   T 76   \u001b[91m☒\u001b[0m 80  \n",
      "Q 894+56  T 950  \u001b[91m☒\u001b[0m 942 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 634us/step - loss: 1.0343 - acc: 0.6229 - val_loss: 0.9921 - val_acc: 0.6402\n",
      "Q 5+751   T 756  \u001b[91m☒\u001b[0m 755 \n",
      "Q 299+1   T 300  \u001b[91m☒\u001b[0m 399 \n",
      "Q 535+25  T 560  \u001b[91m☒\u001b[0m 556 \n",
      "Q 783+92  T 875  \u001b[92m☑\u001b[0m 875 \n",
      "Q 13+492  T 505  \u001b[91m☒\u001b[0m 411 \n",
      "Q 16+62   T 78   \u001b[91m☒\u001b[0m 76  \n",
      "Q 58+843  T 901  \u001b[91m☒\u001b[0m 818 \n",
      "Q 83+246  T 329  \u001b[91m☒\u001b[0m 321 \n",
      "Q 759+567 T 1326 \u001b[91m☒\u001b[0m 1323\n",
      "Q 657+33  T 690  \u001b[91m☒\u001b[0m 681 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 643us/step - loss: 0.9292 - acc: 0.6659 - val_loss: 0.8852 - val_acc: 0.6842\n",
      "Q 6+403   T 409  \u001b[91m☒\u001b[0m 407 \n",
      "Q 557+59  T 616  \u001b[91m☒\u001b[0m 613 \n",
      "Q 9+293   T 302  \u001b[91m☒\u001b[0m 300 \n",
      "Q 144+233 T 377  \u001b[91m☒\u001b[0m 374 \n",
      "Q 670+626 T 1296 \u001b[91m☒\u001b[0m 1390\n",
      "Q 942+586 T 1528 \u001b[91m☒\u001b[0m 1533\n",
      "Q 843+95  T 938  \u001b[91m☒\u001b[0m 944 \n",
      "Q 28+789  T 817  \u001b[91m☒\u001b[0m 814 \n",
      "Q 579+93  T 672  \u001b[91m☒\u001b[0m 675 \n",
      "Q 477+532 T 1009 \u001b[91m☒\u001b[0m 1010\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 631us/step - loss: 0.8432 - acc: 0.6993 - val_loss: 0.8162 - val_acc: 0.6992\n",
      "Q 97+139  T 236  \u001b[92m☑\u001b[0m 236 \n",
      "Q 897+69  T 966  \u001b[91m☒\u001b[0m 963 \n",
      "Q 69+330  T 399  \u001b[91m☒\u001b[0m 309 \n",
      "Q 81+652  T 733  \u001b[91m☒\u001b[0m 739 \n",
      "Q 984+92  T 1076 \u001b[91m☒\u001b[0m 1072\n",
      "Q 611+378 T 989  \u001b[91m☒\u001b[0m 999 \n",
      "Q 848+156 T 1004 \u001b[91m☒\u001b[0m 1002\n",
      "Q 50+775  T 825  \u001b[91m☒\u001b[0m 829 \n",
      "Q 4+750   T 754  \u001b[91m☒\u001b[0m 755 \n",
      "Q 681+600 T 1281 \u001b[91m☒\u001b[0m 1287\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 634us/step - loss: 0.7732 - acc: 0.7274 - val_loss: 0.7459 - val_acc: 0.7324\n",
      "Q 984+92  T 1076 \u001b[91m☒\u001b[0m 1073\n",
      "Q 570+877 T 1447 \u001b[91m☒\u001b[0m 1458\n",
      "Q 126+83  T 209  \u001b[91m☒\u001b[0m 210 \n",
      "Q 426+910 T 1336 \u001b[91m☒\u001b[0m 1348\n",
      "Q 312+99  T 411  \u001b[91m☒\u001b[0m 410 \n",
      "Q 462+891 T 1353 \u001b[91m☒\u001b[0m 1350\n",
      "Q 34+17   T 51   \u001b[91m☒\u001b[0m 59  \n",
      "Q 73+487  T 560  \u001b[91m☒\u001b[0m 554 \n",
      "Q 535+811 T 1346 \u001b[91m☒\u001b[0m 1356\n",
      "Q 76+478  T 554  \u001b[91m☒\u001b[0m 556 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 642us/step - loss: 0.7014 - acc: 0.7552 - val_loss: 0.6711 - val_acc: 0.7611\n",
      "Q 598+9   T 607  \u001b[91m☒\u001b[0m 506 \n",
      "Q 82+945  T 1027 \u001b[91m☒\u001b[0m 1024\n",
      "Q 840+96  T 936  \u001b[91m☒\u001b[0m 939 \n",
      "Q 7+846   T 853  \u001b[92m☑\u001b[0m 853 \n",
      "Q 4+812   T 816  \u001b[91m☒\u001b[0m 817 \n",
      "Q 56+897  T 953  \u001b[92m☑\u001b[0m 953 \n",
      "Q 944+242 T 1186 \u001b[91m☒\u001b[0m 1188\n",
      "Q 172+79  T 251  \u001b[91m☒\u001b[0m 258 \n",
      "Q 765+457 T 1222 \u001b[91m☒\u001b[0m 1224\n",
      "Q 4+725   T 729  \u001b[91m☒\u001b[0m 739 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 637us/step - loss: 0.5955 - acc: 0.7887 - val_loss: 0.5178 - val_acc: 0.8152\n",
      "Q 1+139   T 140  \u001b[91m☒\u001b[0m 130 \n",
      "Q 622+147 T 769  \u001b[91m☒\u001b[0m 770 \n",
      "Q 97+530  T 627  \u001b[91m☒\u001b[0m 629 \n",
      "Q 238+974 T 1212 \u001b[91m☒\u001b[0m 1110\n",
      "Q 183+1   T 184  \u001b[92m☑\u001b[0m 184 \n",
      "Q 16+200  T 216  \u001b[92m☑\u001b[0m 216 \n",
      "Q 799+1   T 800  \u001b[91m☒\u001b[0m 790 \n",
      "Q 300+25  T 325  \u001b[91m☒\u001b[0m 324 \n",
      "Q 62+648  T 710  \u001b[91m☒\u001b[0m 700 \n",
      "Q 7+59    T 66   \u001b[92m☑\u001b[0m 66  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 634us/step - loss: 0.4280 - acc: 0.8560 - val_loss: 0.3668 - val_acc: 0.8838\n",
      "Q 869+943 T 1812 \u001b[91m☒\u001b[0m 1822\n",
      "Q 31+179  T 210  \u001b[92m☑\u001b[0m 210 \n",
      "Q 259+66  T 325  \u001b[91m☒\u001b[0m 324 \n",
      "Q 923+947 T 1870 \u001b[92m☑\u001b[0m 1870\n",
      "Q 58+843  T 901  \u001b[92m☑\u001b[0m 901 \n",
      "Q 72+489  T 561  \u001b[91m☒\u001b[0m 562 \n",
      "Q 7+498   T 505  \u001b[91m☒\u001b[0m 504 \n",
      "Q 937+639 T 1576 \u001b[91m☒\u001b[0m 1586\n",
      "Q 133+232 T 365  \u001b[92m☑\u001b[0m 365 \n",
      "Q 76+883  T 959  \u001b[91m☒\u001b[0m 950 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 635us/step - loss: 0.2996 - acc: 0.9169 - val_loss: 0.2547 - val_acc: 0.9318\n",
      "Q 70+219  T 289  \u001b[92m☑\u001b[0m 289 \n",
      "Q 31+492  T 523  \u001b[92m☑\u001b[0m 523 \n",
      "Q 99+641  T 740  \u001b[91m☒\u001b[0m 730 \n",
      "Q 798+174 T 972  \u001b[91m☒\u001b[0m 971 \n",
      "Q 834+22  T 856  \u001b[92m☑\u001b[0m 856 \n",
      "Q 506+750 T 1256 \u001b[91m☒\u001b[0m 1246\n",
      "Q 88+944  T 1032 \u001b[92m☑\u001b[0m 1032\n",
      "Q 344+43  T 387  \u001b[92m☑\u001b[0m 387 \n",
      "Q 666+656 T 1322 \u001b[92m☑\u001b[0m 1322\n",
      "Q 20+150  T 170  \u001b[92m☑\u001b[0m 170 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 28s 630us/step - loss: 0.2114 - acc: 0.9533 - val_loss: 0.1787 - val_acc: 0.9636\n",
      "Q 62+350  T 412  \u001b[92m☑\u001b[0m 412 \n",
      "Q 56+622  T 678  \u001b[92m☑\u001b[0m 678 \n",
      "Q 453+130 T 583  \u001b[92m☑\u001b[0m 583 \n",
      "Q 58+412  T 470  \u001b[92m☑\u001b[0m 470 \n",
      "Q 800+32  T 832  \u001b[92m☑\u001b[0m 832 \n",
      "Q 52+85   T 137  \u001b[92m☑\u001b[0m 137 \n",
      "Q 294+69  T 363  \u001b[92m☑\u001b[0m 363 \n",
      "Q 451+936 T 1387 \u001b[92m☑\u001b[0m 1387\n",
      "Q 481+452 T 933  \u001b[92m☑\u001b[0m 933 \n",
      "Q 591+85  T 676  \u001b[92m☑\u001b[0m 676 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 632us/step - loss: 0.1531 - acc: 0.9706 - val_loss: 0.1408 - val_acc: 0.9711\n",
      "Q 108+60  T 168  \u001b[92m☑\u001b[0m 168 \n",
      "Q 865+248 T 1113 \u001b[92m☑\u001b[0m 1113\n",
      "Q 42+53   T 95   \u001b[91m☒\u001b[0m 96  \n",
      "Q 96+167  T 263  \u001b[92m☑\u001b[0m 263 \n",
      "Q 79+44   T 123  \u001b[92m☑\u001b[0m 123 \n",
      "Q 511+43  T 554  \u001b[92m☑\u001b[0m 554 \n",
      "Q 149+403 T 552  \u001b[92m☑\u001b[0m 552 \n",
      "Q 307+36  T 343  \u001b[92m☑\u001b[0m 343 \n",
      "Q 149+89  T 238  \u001b[92m☑\u001b[0m 238 \n",
      "Q 232+71  T 303  \u001b[92m☑\u001b[0m 303 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 644us/step - loss: 0.1232 - acc: 0.9761 - val_loss: 0.1053 - val_acc: 0.9813\n",
      "Q 650+2   T 652  \u001b[92m☑\u001b[0m 652 \n",
      "Q 53+205  T 258  \u001b[92m☑\u001b[0m 258 \n",
      "Q 461+47  T 508  \u001b[92m☑\u001b[0m 508 \n",
      "Q 978+10  T 988  \u001b[92m☑\u001b[0m 988 \n",
      "Q 858+555 T 1413 \u001b[92m☑\u001b[0m 1413\n",
      "Q 56+622  T 678  \u001b[92m☑\u001b[0m 678 \n",
      "Q 426+414 T 840  \u001b[92m☑\u001b[0m 840 \n",
      "Q 48+198  T 246  \u001b[91m☒\u001b[0m 256 \n",
      "Q 46+248  T 294  \u001b[92m☑\u001b[0m 294 \n",
      "Q 557+333 T 890  \u001b[92m☑\u001b[0m 890 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 636us/step - loss: 0.0902 - acc: 0.9855 - val_loss: 0.0877 - val_acc: 0.9825\n",
      "Q 606+11  T 617  \u001b[92m☑\u001b[0m 617 \n",
      "Q 578+305 T 883  \u001b[92m☑\u001b[0m 883 \n",
      "Q 87+359  T 446  \u001b[92m☑\u001b[0m 446 \n",
      "Q 479+604 T 1083 \u001b[92m☑\u001b[0m 1083\n",
      "Q 679+96  T 775  \u001b[92m☑\u001b[0m 775 \n",
      "Q 81+341  T 422  \u001b[92m☑\u001b[0m 422 \n",
      "Q 408+564 T 972  \u001b[92m☑\u001b[0m 972 \n",
      "Q 2+546   T 548  \u001b[92m☑\u001b[0m 548 \n",
      "Q 454+336 T 790  \u001b[92m☑\u001b[0m 790 \n",
      "Q 45+586  T 631  \u001b[92m☑\u001b[0m 631 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 626us/step - loss: 0.0742 - acc: 0.9882 - val_loss: 0.0664 - val_acc: 0.9885\n",
      "Q 20+43   T 63   \u001b[92m☑\u001b[0m 63  \n",
      "Q 23+77   T 100  \u001b[92m☑\u001b[0m 100 \n",
      "Q 526+286 T 812  \u001b[92m☑\u001b[0m 812 \n",
      "Q 147+441 T 588  \u001b[92m☑\u001b[0m 588 \n",
      "Q 691+189 T 880  \u001b[92m☑\u001b[0m 880 \n",
      "Q 540+57  T 597  \u001b[92m☑\u001b[0m 597 \n",
      "Q 10+702  T 712  \u001b[92m☑\u001b[0m 712 \n",
      "Q 1+827   T 828  \u001b[92m☑\u001b[0m 828 \n",
      "Q 553+19  T 572  \u001b[92m☑\u001b[0m 572 \n",
      "Q 481+962 T 1443 \u001b[92m☑\u001b[0m 1443\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 628us/step - loss: 0.0579 - acc: 0.9918 - val_loss: 0.0540 - val_acc: 0.9921\n",
      "Q 451+540 T 991  \u001b[92m☑\u001b[0m 991 \n",
      "Q 1+197   T 198  \u001b[92m☑\u001b[0m 198 \n",
      "Q 258+272 T 530  \u001b[92m☑\u001b[0m 530 \n",
      "Q 54+757  T 811  \u001b[92m☑\u001b[0m 811 \n",
      "Q 48+44   T 92   \u001b[92m☑\u001b[0m 92  \n",
      "Q 362+94  T 456  \u001b[92m☑\u001b[0m 456 \n",
      "Q 91+81   T 172  \u001b[92m☑\u001b[0m 172 \n",
      "Q 385+19  T 404  \u001b[92m☑\u001b[0m 404 \n",
      "Q 777+80  T 857  \u001b[92m☑\u001b[0m 857 \n",
      "Q 515+8   T 523  \u001b[92m☑\u001b[0m 523 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 627us/step - loss: 0.0703 - acc: 0.9844 - val_loss: 0.0519 - val_acc: 0.9907\n",
      "Q 38+70   T 108  \u001b[92m☑\u001b[0m 108 \n",
      "Q 17+557  T 574  \u001b[92m☑\u001b[0m 574 \n",
      "Q 4+850   T 854  \u001b[92m☑\u001b[0m 854 \n",
      "Q 383+256 T 639  \u001b[92m☑\u001b[0m 639 \n",
      "Q 69+32   T 101  \u001b[92m☑\u001b[0m 101 \n",
      "Q 872+15  T 887  \u001b[92m☑\u001b[0m 887 \n",
      "Q 334+329 T 663  \u001b[92m☑\u001b[0m 663 \n",
      "Q 21+71   T 92   \u001b[92m☑\u001b[0m 92  \n",
      "Q 870+7   T 877  \u001b[92m☑\u001b[0m 877 \n",
      "Q 320+620 T 940  \u001b[92m☑\u001b[0m 940 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 623us/step - loss: 0.0385 - acc: 0.9956 - val_loss: 0.0379 - val_acc: 0.9943\n",
      "Q 334+32  T 366  \u001b[92m☑\u001b[0m 366 \n",
      "Q 5+89    T 94   \u001b[92m☑\u001b[0m 94  \n",
      "Q 249+72  T 321  \u001b[92m☑\u001b[0m 321 \n",
      "Q 77+834  T 911  \u001b[92m☑\u001b[0m 911 \n",
      "Q 38+631  T 669  \u001b[92m☑\u001b[0m 669 \n",
      "Q 491+87  T 578  \u001b[92m☑\u001b[0m 578 \n",
      "Q 461+969 T 1430 \u001b[92m☑\u001b[0m 1430\n",
      "Q 106+898 T 1004 \u001b[92m☑\u001b[0m 1004\n",
      "Q 74+704  T 778  \u001b[92m☑\u001b[0m 778 \n",
      "Q 56+697  T 753  \u001b[92m☑\u001b[0m 753 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 637us/step - loss: 0.0312 - acc: 0.9969 - val_loss: 0.0488 - val_acc: 0.9887\n",
      "Q 61+721  T 782  \u001b[92m☑\u001b[0m 782 \n",
      "Q 775+800 T 1575 \u001b[92m☑\u001b[0m 1575\n",
      "Q 56+927  T 983  \u001b[92m☑\u001b[0m 983 \n",
      "Q 205+61  T 266  \u001b[92m☑\u001b[0m 266 \n",
      "Q 65+772  T 837  \u001b[92m☑\u001b[0m 837 \n",
      "Q 486+62  T 548  \u001b[92m☑\u001b[0m 548 \n",
      "Q 128+0   T 128  \u001b[92m☑\u001b[0m 128 \n",
      "Q 310+139 T 449  \u001b[92m☑\u001b[0m 449 \n",
      "Q 975+234 T 1209 \u001b[92m☑\u001b[0m 1209\n",
      "Q 3+87    T 90   \u001b[91m☒\u001b[0m 80  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 623us/step - loss: 0.0607 - acc: 0.9841 - val_loss: 0.0949 - val_acc: 0.9721\n",
      "Q 51+83   T 134  \u001b[92m☑\u001b[0m 134 \n",
      "Q 955+776 T 1731 \u001b[92m☑\u001b[0m 1731\n",
      "Q 121+50  T 171  \u001b[92m☑\u001b[0m 171 \n",
      "Q 269+399 T 668  \u001b[92m☑\u001b[0m 668 \n",
      "Q 638+928 T 1566 \u001b[92m☑\u001b[0m 1566\n",
      "Q 501+352 T 853  \u001b[92m☑\u001b[0m 853 \n",
      "Q 0+67    T 67   \u001b[92m☑\u001b[0m 67  \n",
      "Q 73+748  T 821  \u001b[92m☑\u001b[0m 821 \n",
      "Q 672+290 T 962  \u001b[92m☑\u001b[0m 962 \n",
      "Q 6+581   T 587  \u001b[92m☑\u001b[0m 587 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 625us/step - loss: 0.0281 - acc: 0.9960 - val_loss: 0.0236 - val_acc: 0.9965\n",
      "Q 478+604 T 1082 \u001b[92m☑\u001b[0m 1082\n",
      "Q 84+211  T 295  \u001b[92m☑\u001b[0m 295 \n",
      "Q 450+89  T 539  \u001b[92m☑\u001b[0m 539 \n",
      "Q 849+4   T 853  \u001b[92m☑\u001b[0m 853 \n",
      "Q 73+992  T 1065 \u001b[92m☑\u001b[0m 1065\n",
      "Q 844+80  T 924  \u001b[92m☑\u001b[0m 924 \n",
      "Q 0+757   T 757  \u001b[92m☑\u001b[0m 757 \n",
      "Q 45+487  T 532  \u001b[92m☑\u001b[0m 532 \n",
      "Q 44+519  T 563  \u001b[92m☑\u001b[0m 563 \n",
      "Q 235+23  T 258  \u001b[92m☑\u001b[0m 258 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 640us/step - loss: 0.0172 - acc: 0.9990 - val_loss: 0.0198 - val_acc: 0.9974\n",
      "Q 129+238 T 367  \u001b[92m☑\u001b[0m 367 \n",
      "Q 41+883  T 924  \u001b[92m☑\u001b[0m 924 \n",
      "Q 889+96  T 985  \u001b[92m☑\u001b[0m 985 \n",
      "Q 206+6   T 212  \u001b[92m☑\u001b[0m 212 \n",
      "Q 618+738 T 1356 \u001b[92m☑\u001b[0m 1356\n",
      "Q 214+683 T 897  \u001b[92m☑\u001b[0m 897 \n",
      "Q 412+381 T 793  \u001b[91m☒\u001b[0m 893 \n",
      "Q 58+397  T 455  \u001b[92m☑\u001b[0m 455 \n",
      "Q 78+757  T 835  \u001b[92m☑\u001b[0m 835 \n",
      "Q 587+616 T 1203 \u001b[92m☑\u001b[0m 1203\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 633us/step - loss: 0.0160 - acc: 0.9990 - val_loss: 0.0201 - val_acc: 0.9965\n",
      "Q 814+83  T 897  \u001b[92m☑\u001b[0m 897 \n",
      "Q 511+17  T 528  \u001b[92m☑\u001b[0m 528 \n",
      "Q 979+1   T 980  \u001b[92m☑\u001b[0m 980 \n",
      "Q 18+495  T 513  \u001b[92m☑\u001b[0m 513 \n",
      "Q 973+265 T 1238 \u001b[92m☑\u001b[0m 1238\n",
      "Q 20+416  T 436  \u001b[92m☑\u001b[0m 436 \n",
      "Q 35+738  T 773  \u001b[92m☑\u001b[0m 773 \n",
      "Q 9+103   T 112  \u001b[92m☑\u001b[0m 112 \n",
      "Q 2+875   T 877  \u001b[92m☑\u001b[0m 877 \n",
      "Q 48+29   T 77   \u001b[92m☑\u001b[0m 77  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 642us/step - loss: 0.0362 - acc: 0.9912 - val_loss: 0.0216 - val_acc: 0.9958\n",
      "Q 551+837 T 1388 \u001b[92m☑\u001b[0m 1388\n",
      "Q 178+418 T 596  \u001b[91m☒\u001b[0m 696 \n",
      "Q 5+278   T 283  \u001b[92m☑\u001b[0m 283 \n",
      "Q 389+792 T 1181 \u001b[92m☑\u001b[0m 1181\n",
      "Q 739+335 T 1074 \u001b[92m☑\u001b[0m 1074\n",
      "Q 853+99  T 952  \u001b[92m☑\u001b[0m 952 \n",
      "Q 135+70  T 205  \u001b[92m☑\u001b[0m 205 \n",
      "Q 911+7   T 918  \u001b[92m☑\u001b[0m 918 \n",
      "Q 39+84   T 123  \u001b[92m☑\u001b[0m 123 \n",
      "Q 84+511  T 595  \u001b[92m☑\u001b[0m 595 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 28s 630us/step - loss: 0.0233 - acc: 0.9954 - val_loss: 0.0183 - val_acc: 0.9970\n",
      "Q 19+658  T 677  \u001b[92m☑\u001b[0m 677 \n",
      "Q 820+0   T 820  \u001b[92m☑\u001b[0m 820 \n",
      "Q 0+67    T 67   \u001b[92m☑\u001b[0m 67  \n",
      "Q 965+909 T 1874 \u001b[92m☑\u001b[0m 1874\n",
      "Q 49+639  T 688  \u001b[92m☑\u001b[0m 688 \n",
      "Q 80+176  T 256  \u001b[92m☑\u001b[0m 256 \n",
      "Q 875+228 T 1103 \u001b[92m☑\u001b[0m 1103\n",
      "Q 936+32  T 968  \u001b[92m☑\u001b[0m 968 \n",
      "Q 918+35  T 953  \u001b[92m☑\u001b[0m 953 \n",
      "Q 8+309   T 317  \u001b[92m☑\u001b[0m 317 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 636us/step - loss: 0.0109 - acc: 0.9993 - val_loss: 0.0161 - val_acc: 0.9967\n",
      "Q 1+696   T 697  \u001b[92m☑\u001b[0m 697 \n",
      "Q 133+65  T 198  \u001b[92m☑\u001b[0m 198 \n",
      "Q 55+938  T 993  \u001b[92m☑\u001b[0m 993 \n",
      "Q 309+60  T 369  \u001b[92m☑\u001b[0m 369 \n",
      "Q 12+58   T 70   \u001b[92m☑\u001b[0m 70  \n",
      "Q 952+65  T 1017 \u001b[92m☑\u001b[0m 1017\n",
      "Q 466+528 T 994  \u001b[92m☑\u001b[0m 994 \n",
      "Q 426+719 T 1145 \u001b[92m☑\u001b[0m 1145\n",
      "Q 34+120  T 154  \u001b[92m☑\u001b[0m 154 \n",
      "Q 22+28   T 50   \u001b[92m☑\u001b[0m 50  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "19712/45000 [============>.................] - ETA: 15s - loss: 0.0090 - acc: 0.9995"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-916d21ec550e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m               validation_data=(x_val, y_val))\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Select 10 samples from the validation set at random so we can visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018-11-20 14:25:11.915648: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX  \n",
    "2018-11-20 14:25:11.915971: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.  \n",
    "OMP: Error #15: Initializing libiomp5.dylib, but found libiomp5.dylib already initialized.  \n",
    "OMP: Hint: This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://www.intel.com/software/products/support/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/dmlc/xgboost/issues/1715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36co",
   "language": "python",
   "name": "py36co"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
